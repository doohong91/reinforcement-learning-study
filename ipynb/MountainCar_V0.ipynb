{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MountainCar-V0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXLygg6KrchbtTv/7Vfrkq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doohong91/reinforcement-learning-study/blob/main/ipynb/MountainCar_V0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWqdCoHMXPIR"
      },
      "source": [
        "import gym\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#Hyperparameters\n",
        "learning_rate = 0.001\n",
        "gamma = 0.980\n",
        "buffer_limit = 100000\n",
        "batch_size = 2000"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JRPZ30pXPLI"
      },
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self):\n",
        "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
        "\n",
        "    def put(self, data):\n",
        "        self.buffer.append(data)\n",
        "\n",
        "    def sample(self, n):\n",
        "        mini_batch = random.sample(self.buffer, n)\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            s, a, r, s_prime, done_mask = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask_lst.append([done_mask])\n",
        "        \n",
        "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), torch.tensor(done_mask_lst)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCypxkBgtJb"
      },
      "source": [
        "class Qnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Qnet, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 128) \n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "    def sample_action(self, obs, epsilon):\n",
        "        out = self.forward(obs)\n",
        "        coin = random.random()\n",
        "\n",
        "        if coin < epsilon:\n",
        "            return random.randint(0,2)\n",
        "        else : \n",
        "            return out.argmax().item()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOzZFXKYXPOy"
      },
      "source": [
        "def train(q, q_target, memory, optimizer):\n",
        "    for i in range(15):\n",
        "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
        "\n",
        "        q_out = q(s)\n",
        "        q_a = q_out.gather(1,a)\n",
        "\n",
        "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
        "        target = r + gamma * max_q_prime * done_mask\n",
        "        loss = F.smooth_l1_loss(q_a, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfqApF4HEntf"
      },
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "q = Qnet()\n",
        "q_target = Qnet()\n",
        "q_target.load_state_dict(q.state_dict())\n",
        "memory = ReplayBuffer()\n",
        "\n",
        "print_interval = 20\n",
        "score = 0.0 \n",
        "optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
        "render = False\n",
        "max_position = -0.4\n",
        "success = 0\n",
        "count = 0\n",
        "positions = np.ndarray([0,2])\n",
        "\n",
        "for n_epi in range(800):\n",
        "    epsilon = max(0.01, 0.08 - 0.01*(n_epi/100))\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        a = q.sample_action(torch.from_numpy(s).float(), epsilon) \n",
        "        s_prime, r, done, info = env.step(a)\n",
        "        done_mask = 0.0 if done else 1.0\n",
        "\n",
        "        if a != 3:\n",
        "            count += 1\n",
        "\n",
        "        if s_prime[1]>0: #오른쪽으로 가는 속도에 더 큰 리워드를 받도록 한다.\n",
        "            r=((s_prime[0]+0.5)*10)**2/10+15*s_prime[1]-count/400 #위치에 따라 리워드를 이차함수 형태로 가중치를 받는다.\n",
        "        else:\n",
        "            r = ((s_prime[0]+0.5)*10)**2/10-count/400\n",
        "\n",
        "        if s_prime[0] > max_position:\n",
        "            max_position = s_prime[0]\n",
        "            positions = np.append(positions, [[n_epi, max_position]], axis=0)\n",
        "\n",
        "        if s_prime[0] >= 0.5: #flag 위치가 0.5\n",
        "            success += 1 #flag에 닿으면 성공\n",
        "            r = 20 #성공하면 리워드 20을 받는다.\n",
        "        else:\n",
        "            score -= 1\n",
        "\n",
        "        memory.put((s,a,r,s_prime, done_mask))\n",
        "        s = s_prime\n",
        "\n",
        "        if render:\n",
        "            env.render()\n",
        "\n",
        "        if done:\n",
        "            count = 0\n",
        "            max_position = -0.4\n",
        "            break\n",
        "\n",
        "        if success/print_interval*100 == 100:\n",
        "            render = True\n",
        "\n",
        "    if memory.size()>8000:\n",
        "        train(q, q_target, memory, optimizer)\n",
        "\n",
        "    if n_epi%print_interval==0 and n_epi!=0:\n",
        "        q_target.load_state_dict(q.state_dict())\n",
        "        print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%, success rate : {}%\".format(\n",
        "        n_epi, score/print_interval, memory.size(), epsilon*100, success/print_interval*100))\n",
        "        score = 0.0\n",
        "        success = 0\n",
        "\n",
        "plt.figure(1, figsize=[10,5])\n",
        "plt.plot(positions[:,0], positions[:,1])\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Furthest Position')\n",
        "\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJOV6LPwe9T3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoFGO6_Ve9cc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-yd_p3Ae9gj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TP736bNM2su"
      },
      "source": [
        "# libraries\n",
        "import gym\n",
        "import collections\n",
        "import random\n",
        "\n",
        "# pytorch library is used for deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# hyperparameters\n",
        "learning_rate = 0.001\n",
        "gamma = 0.98\n",
        "buffer_limit = 100000        # size of replay buffer\n",
        "batch_size = 128"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJCWL6wBMX4W"
      },
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self):\n",
        "        self.buffer = collections.deque(maxlen=buffer_limit)    # double-ended queue\n",
        "    \n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "\n",
        "    def sample(self, n):\n",
        "        mini_batch = random.sample(self.buffer, n)\n",
        "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
        "\n",
        "        for transition in mini_batch:\n",
        "            s, a, r, s_prime, done_mask = transition\n",
        "            s_lst.append(s)\n",
        "            a_lst.append([a])\n",
        "            r_lst.append([r])\n",
        "            s_prime_lst.append(s_prime)\n",
        "            done_mask_lst.append([done_mask])\n",
        "\n",
        "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "               torch.tensor(done_mask_lst)\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFl9qPtUMzbY"
      },
      "source": [
        "class DuelingQnet(nn.Module):\n",
        "    def __init__(self, n_obs, n_act):\n",
        "        super(DuelingQnet, self).__init__()\n",
        "        self.fc1 = nn.Linear(n_obs, 128)\n",
        "        self.fc_value = nn.Linear(128, 128)\n",
        "        self.fc_adv = nn.Linear(128, 128)\n",
        "        self.value = nn.Linear(128, 1)\n",
        "        self.adv = nn.Linear(128, n_act)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        v = F.relu(self.fc_value(x))\n",
        "        a = F.relu(self.fc_adv(x))\n",
        "        v = self.value(v)\n",
        "        a = self.adv(a)\n",
        "        a_avg = torch.mean(a)\n",
        "        q = v + a - a_avg\n",
        "        return q\n",
        "\n",
        "    def sample_action(self, obs, epsilon):\n",
        "        out = self.forward(obs)\n",
        "        coin = random.random()\n",
        "        if coin < epsilon:\n",
        "            return random.randint(0,1)\n",
        "        else : \n",
        "            return out.argmax().item()  "
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq8Ew83OS950"
      },
      "source": [
        "class Qnet(nn.Module):\n",
        "    def __init__(self, n_obs, n_act):\n",
        "        super(Qnet, self).__init__()\n",
        "        self.fc1 = nn.Linear(n_obs, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, n_act)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "      \n",
        "    def sample_action(self, obs, epsilon):\n",
        "        out = self.forward(obs)\n",
        "        coin = random.random()\n",
        "        if coin < epsilon:\n",
        "            return random.randint(0,1)\n",
        "        else : \n",
        "            return out.argmax().item()   "
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdDjgbldMzep"
      },
      "source": [
        "def train(q, q_target, memory, optimizer):\n",
        "    for i in range(20):\n",
        "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
        "\n",
        "        q_out = q(s)\n",
        "        q_a = q_out.gather(1,a)\n",
        "\n",
        "        # DQN\n",
        "        # max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
        "\n",
        "        # Double DQN\n",
        "        argmax_Q = q(s_prime).max(1)[1].unsqueeze(1)\n",
        "        max_q_prime = q_target(s_prime).gather(1, argmax_Q)\n",
        "\n",
        "        target = r + gamma * max_q_prime * done_mask\n",
        "        \n",
        "        # MSE Loss\n",
        "        # loss = F.mse_loss(q_a, target)\n",
        "\n",
        "        # Smooth L1 Loss\n",
        "        loss = F.smooth_l1_loss(q_a, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A36g7zZlqUUQ"
      },
      "source": [
        "# reward function reference: https://github.com/shivaverma/OpenAIGym/blob/master/mountain-car/MountainCar-v0.py\n",
        "\n",
        "def get_reward(state):\n",
        "\n",
        "    if state[0] >= 0.5:  # Car has reached the goal\n",
        "        return 10, 1\n",
        "    if state[0] > -0.4:\n",
        "        return (1+state[0])**2, 0\n",
        "    return -1, 0"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-rJ0ItGdIFO"
      },
      "source": [
        ""
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJVIbFuIdIHE"
      },
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "\n",
        "q = DuelingQnet(env.observation_space.shape[0], env.action_space.n)\n",
        "q_target = DuelingQnet(env.observation_space.shape[0], env.action_space.n)\n",
        "q_target.load_state_dict(q.state_dict())\n",
        "memory = ReplayBuffer()\n",
        "\n",
        "print_interval = 20\n",
        "score = reached = 0.0\n",
        "logs = []\n",
        "optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
        "\n",
        "for n_epi in range(3000):\n",
        "    epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
        "    s = env.reset()\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        a = q.sample_action(torch.from_numpy(s).float(), epsilon)\n",
        "        s_prime, r, done, info = env.step(a)\n",
        "        done_mask = 0.0 if done else 1.0\n",
        "\n",
        "        # r, goal = get_reward(s_prime)\n",
        "        score += r\n",
        "        reached += 0 if r < 0 else 1\n",
        "\n",
        "        memory.put((s,a,r/100.0,s_prime, done_mask))\n",
        "        s = s_prime\n",
        "        \n",
        "        if done:\n",
        "            break\n",
        "        \n",
        "    if memory.size() > 8000:\n",
        "        train(q, q_target, memory, optimizer)\n",
        "\n",
        "    if n_epi%print_interval==0 and n_epi!=0:\n",
        "        q_target.load_state_dict(q.state_dict())\n",
        "        print(f\"n_episode: {n_epi}, score: {score:.1f}, reached: {reached:.2f}%, n_buffer: {memory.size()}, eps: {epsilon*100:.1f}%\")\n",
        "\n",
        "    logs.append(score)\n",
        "    score = reached = 0.0\n",
        "    \n",
        "\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "84fiqpgHMzi9",
        "outputId": "d5b8ac51-36a9-46cf-d93d-dd01b65dd8d3"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(logs)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Return')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Return')"
            ]
          },
          "metadata": {},
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqDI2mn15spX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtBv1tDP5sss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IINS4GJP5svt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eprJPHu5szV"
      },
      "source": [
        "class PolicyNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layer_size=128):\n",
        "        super(PolicyNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_layer_size)\n",
        "        self.fc2 = torch.nn.Linear(hidden_layer_size, output_size)\n",
        "        self.softmax = torch.nn.Softmax(dim=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.from_numpy(x).float()\n",
        "        return self.softmax(self.fc2(torch.nn.functional.relu(self.fc1(x))))\n",
        "\n",
        "    def get_action_and_logp(self, x):\n",
        "        action_prob = self.forward(x)\n",
        "        m = torch.distributions.Categorical(action_prob)\n",
        "        action = m.sample()\n",
        "        logp = m.log_prob(action)\n",
        "        return action.item(), logp\n",
        "\n",
        "    def act(self, x):\n",
        "        action, _ = self.get_action_and_logp(x)\n",
        "        return action\n",
        "\n",
        "class ValueNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_layer_size=128):\n",
        "        super(ValueNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_layer_size)\n",
        "        self.fc2 = torch.nn.Linear(hidden_layer_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.from_numpy(x).float()\n",
        "        return self.fc2(torch.nn.functional.relu(self.fc1(x)))\n",
        "\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lysuXPJq5s1Z"
      },
      "source": [
        "def policyGradient(env, max_num_steps=1000, gamma=0.98, lr=0.01,\n",
        "                   num_traj=10, num_iter=200):\n",
        "    input_size = env.observation_space.shape[0]\n",
        "    output_size = env.action_space.n\n",
        "    Trajectory = namedtuple('Trajectory', 'states actions rewards dones logp')\n",
        "\n",
        "    def collect_trajectory():\n",
        "        state_list = []\n",
        "        action_list = []\n",
        "        reward_list = []\n",
        "        dones_list = []\n",
        "        logp_list = []\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        steps = 0\n",
        "        while not done:\n",
        "            action, logp = policy.get_action_and_logp(state)\n",
        "            newstate, reward, done, _ = env.step(action)\n",
        "            state_list.append(state)\n",
        "            action_list.append(action)\n",
        "            reward_list.append(reward)\n",
        "            dones_list.append(done)\n",
        "            logp_list.append(logp)\n",
        "            steps += 1\n",
        "            state = newstate\n",
        "\n",
        "        traj = Trajectory(states=state_list, actions=action_list,\n",
        "                          rewards=reward_list, logp=logp_list, dones=dones_list)\n",
        "        return traj\n",
        "\n",
        "    def calc_returns(rewards):\n",
        "        dis_rewards = [gamma**i * r for i, r in enumerate(rewards)]\n",
        "        return [sum(dis_rewards[i:]) for i in range(len(dis_rewards))]\n",
        "\n",
        "    policy = PolicyNet(input_size, output_size)\n",
        "    policy_optimizer = torch.optim.Adam(policy.parameters(), lr=lr)\n",
        "\n",
        "    value = ValueNet(input_size)\n",
        "    value_optimizer = torch.optim.Adam(value.parameters(), lr=lr)\n",
        "\n",
        "    mean_return_list = []\n",
        "    for it in range(num_iter):\n",
        "        traj_list = [collect_trajectory() for _ in range(num_traj)]\n",
        "        returns = [calc_returns(traj.rewards) for traj in traj_list]\n",
        "\n",
        "        #====================================#\n",
        "        # policy gradient with base function #\n",
        "        #====================================#\n",
        "        policy_loss_terms = [-1. * traj.logp[j] * (returns[i][j] - value(traj.states[j]))\n",
        "                            for i, traj in enumerate(traj_list) for j in range(len(traj.actions))]\n",
        "\n",
        "        #====================================#\n",
        "        # policy gradient with reward-to-go  #\n",
        "        #====================================#\n",
        "        #policy_loss_terms = [-1. * traj.logp[j] * (torch.Tensor([returns[i][j]]))\n",
        "        #                     for i, traj in enumerate(traj_list) for j in range(len(traj.actions))]\n",
        "\n",
        "        #====================================#\n",
        "        # policy gradient                    #\n",
        "        #====================================#\n",
        "        # policy_loss_terms = [-1. * traj.logp[j] * (torch.Tensor([returns[i][0]]))\n",
        "        #                      for i, traj in enumerate(traj_list) for j in range(len(traj.actions))]\n",
        "\n",
        "        policy_loss = 1. / num_traj * torch.cat(policy_loss_terms).sum()\n",
        "        policy_optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        policy_optimizer.step()\n",
        "\n",
        "        value_loss_terms = [1. / len(traj.actions) * (value(traj.states[j]) - returns[i][j])**2.\n",
        "                            for i, traj in enumerate(traj_list) for j in range(len(traj.actions))]\n",
        "        value_loss = 1. / num_traj * torch.cat(value_loss_terms).sum()\n",
        "        value_optimizer.zero_grad()\n",
        "        value_loss.backward()\n",
        "        value_optimizer.step()\n",
        "\n",
        "        mean_return = 1. / num_traj * sum([traj_returns[0] for traj_returns in returns])\n",
        "        mean_return_list.append(mean_return)\n",
        "        if it % 10 == 0:\n",
        "            print('Iteration {}: Mean Return = {}'.format(it, mean_return))\n",
        "\n",
        "    return policy, mean_return_list"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDMktmQy5s4J",
        "outputId": "1b28f159-a461-41dc-d032-834d5c0748c0"
      },
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "agent, mean_return_list = policyGradient(env, num_iter=500, gamma=1.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Mean Return = -200.0\n",
            "Iteration 10: Mean Return = -200.0\n",
            "Iteration 20: Mean Return = -200.0\n",
            "Iteration 30: Mean Return = -200.0\n",
            "Iteration 40: Mean Return = -200.0\n",
            "Iteration 50: Mean Return = -200.0\n",
            "Iteration 60: Mean Return = -200.0\n",
            "Iteration 70: Mean Return = -200.0\n",
            "Iteration 80: Mean Return = -200.0\n",
            "Iteration 90: Mean Return = -200.0\n",
            "Iteration 100: Mean Return = -200.0\n",
            "Iteration 110: Mean Return = -200.0\n",
            "Iteration 120: Mean Return = -200.0\n",
            "Iteration 130: Mean Return = -200.0\n",
            "Iteration 140: Mean Return = -200.0\n",
            "Iteration 150: Mean Return = -200.0\n",
            "Iteration 160: Mean Return = -200.0\n",
            "Iteration 170: Mean Return = -200.0\n",
            "Iteration 180: Mean Return = -200.0\n",
            "Iteration 190: Mean Return = -200.0\n",
            "Iteration 200: Mean Return = -200.0\n",
            "Iteration 210: Mean Return = -200.0\n",
            "Iteration 220: Mean Return = -200.0\n",
            "Iteration 230: Mean Return = -200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9H2fP5B5s7C"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(logs)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Average Return')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrIuNo8a5tA7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdwHTbtV5tEo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsPULehXSuvd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}